{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bea14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "esg_csv = \"/workspaces/ginappedrosa_project_test/sp500_esg_ceo_info-filtered.csv\"  \n",
    "esg_df = pd.read_csv(esg_csv)\n",
    "\n",
    "print(\"Columnas CSV ESG:\", esg_df.columns)\n",
    "print(\"N√∫mero de tickers en CSV:\", esg_df[\"Ticker\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a8329",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Seleccionamos solo 50 tickers de prueba\n",
    "tickers = esg_df[\"Ticker\"].dropna().unique().tolist()[:50]\n",
    "\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2025-08-30\"\n",
    "\n",
    "all_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fc324",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 50\n",
    "for i in range(0, len(tickers), batch_size):\n",
    "    batch = tickers[i:i+batch_size]\n",
    "    print(f\"\\nDescargando batch {i//batch_size + 1} de {len(tickers)//batch_size + 1}...\")\n",
    "    \n",
    "    try:\n",
    "        df = yf.download(\n",
    "            batch,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            progress=False,\n",
    "            auto_adjust=False  # üå∏ aseguramos que baje \"Adj Close\"\n",
    "        )\n",
    "        \n",
    "        # Pasamos de columnas multi-√≠ndice a columnas simples\n",
    "        df = df.stack(level=1).reset_index()\n",
    "        df.rename(columns={\"level_1\": \"Ticker\"}, inplace=True)\n",
    "        \n",
    "        all_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en batch {i//batch_size + 1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87f61e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Unimos todos los datos financieros\n",
    "fin_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Datos financieros descargados: {fin_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc485f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Unimos con ESG (por ticker)\n",
    "dataset_final = pd.merge(fin_df, esg_df, on=\"Ticker\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd132e00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos features de volatilidad\n",
    "dataset_final[\"Daily_Return\"] = dataset_final.groupby(\"Ticker\")[\"Adj Close\"].pct_change()\n",
    "dataset_final[\"Daily_Volatility\"] = (\n",
    "    dataset_final.groupby(\"Ticker\")[\"Daily_Return\"]\n",
    "    .rolling(5)\n",
    "    .std()\n",
    "    .reset_index(0, drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddde503",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Guardar CSV final\n",
    "dataset_final.to_csv(\"dataset_final.csv\", index=False)\n",
    "\n",
    "print(f\"\\nüå∏ Dataset guardado como 'dataset_final.csv'\")\n",
    "print(\"Shape final:\", dataset_final.shape)\n",
    "print(\"\\nPrimeras filas:\\n\", dataset_final.head())\n",
    "\n",
    "dataset_final.info()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
